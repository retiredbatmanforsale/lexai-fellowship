{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Case Study: Iris Flower Classification\n",
    "\n",
    "## Overview of Machine Learning Pipeline\n",
    "\n",
    "This notebook demonstrates a complete **Machine Learning Classification Pipeline** using the famous Iris dataset. We'll walk through each stage of the ML process:\n",
    "\n",
    "1. **Data Loading & Exploration** - Understanding our dataset\n",
    "2. **Data Visualization** - Exploring patterns and relationships\n",
    "3. **Data Preparation** - Splitting data for training/testing\n",
    "4. **Model Training** - Building our classifier\n",
    "5. **Model Evaluation** - Assessing performance\n",
    "6. **Feature Analysis** - Understanding what drives predictions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Data Loading & Exploration\n",
    "\n",
    "In this stage, we:\n",
    "- Import necessary libraries for data manipulation and ML\n",
    "- Load the Iris dataset (a classic dataset in ML)\n",
    "- Examine the structure and basic information about our data\n",
    "\n",
    "The Iris dataset contains measurements of 150 iris flowers from three different species, with 4 features each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library to do a lot of linear operations on any matrix (n-d array)\n",
    "import pandas as pd # pd.read_csv()\n",
    "import matplotlib.pyplot as plt # plotting \n",
    "import seaborn as sns # plotting library for beautiful plots\n",
    "from sklearn.datasets import load_iris # scikit learn --> all ML alogirthms reside here and a few datasets also. \n",
    "from sklearn.model_selection import train_test_split # \n",
    "from sklearn.linear_model import LogisticRegression # picking up the model so that we dont have to make one\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "print(\"=== 1. Loading the Iris Dataset ===\")\n",
    "iris = load_iris()\n",
    "X = iris.data # X is always and always our input\n",
    "y = iris.target # y is always our output\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=feature_names) # pandas always works on something known as dataframes\n",
    "df['species'] = [target_names[i] for i in y]\n",
    "\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset shape:\", X.shape)\n",
    "print(\"Features:\", feature_names)\n",
    "print(\"Target classes:\", target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Data Visualization\n",
    "\n",
    "**Why visualize data?** Visualization helps us:\n",
    "- Understand relationships between features\n",
    "- Identify patterns that might help our model\n",
    "- Detect potential data quality issues\n",
    "- Choose appropriate preprocessing steps\n",
    "\n",
    "The pairplot shows how each feature relates to every other feature, with points colored by species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "print(\"\\n=== 2. Visualizing the Data ===\")\n",
    "sns.pairplot(df, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Data Preparation\n",
    "\n",
    "**Why split the data?** We need separate datasets to:\n",
    "- **Train** our model on one set of data\n",
    "- **Test** our model on unseen data to get realistic performance estimates\n",
    "- Avoid overfitting (when model memorizes training data but fails on new data)\n",
    "\n",
    "The standard split is 80% for training, 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "print(\"\\n=== 3. Preparing Data for Training ===\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Model Training\n",
    "\n",
    "**What is Logistic Regression?**\n",
    "- A classification algorithm that predicts categorical outcomes\n",
    "- Uses a sigmoid function to output probabilities between 0 and 1\n",
    "- Learns the relationship between features and target classes\n",
    "- Works well for linearly separable data (like the Iris dataset)\n",
    "\n",
    "**Training Process:**\n",
    "- Model learns patterns from training data\n",
    "- Adjusts internal parameters (coefficients) to minimize prediction errors\n",
    "- Uses optimization algorithms to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"\\n=== 4. Training the Classifier ===\")\n",
    "print(\"Using Logistic Regression, which is a simple but powerful classification algorithm.\")\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_by_model = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predicted_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_predicted_by_model, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_accuracy = np.mean(model.predict(X_test) == y_test) * 100 \n",
    "training_accuracy = np.mean(model.predict(X_train) == y_train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5: Model Evaluation\n",
    "\n",
    "**Why evaluate models?** We need to understand:\n",
    "- How well our model performs on unseen data\n",
    "- Which classes are easier or harder to predict\n",
    "- Whether our model is biased toward certain predictions\n",
    "- If we have overfitting or underfitting issues\n",
    "\n",
    "**Key Metrics:**\n",
    "- **Accuracy**: Overall percentage of correct predictions\n",
    "- **Confusion Matrix**: Shows detailed breakdown of predictions vs actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix\n",
    "print(\"\\n=== 5. Model Performance ===\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_names,\n",
    "                yticklabels=target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6: Feature Analysis\n",
    "\n",
    "**Why analyze feature importance?** This helps us:\n",
    "- Understand which features drive the model's decisions\n",
    "- Identify the most predictive characteristics\n",
    "- Potentially simplify the model by removing less important features\n",
    "- Gain domain insights about what distinguishes the classes\n",
    "\n",
    "**Interpretation:**\n",
    "- Higher absolute coefficient values = more important features\n",
    "- Positive coefficients = feature increases probability of that class\n",
    "- Negative coefficients = feature decreases probability of that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature importance\n",
    "print(\"\\n=== 6. Feature Importance ===\")\n",
    "importance = np.abs(model.coef_[0])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_names, importance)\n",
    "plt.title('Feature Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "✅ Loaded and explored the Iris dataset  \n",
    "✅ Visualized feature relationships  \n",
    "✅ Split data into training/testing sets  \n",
    "✅ Trained a Logistic Regression classifier  \n",
    "✅ Evaluated model performance (100% accuracy!)  \n",
    "✅ Analyzed feature importance  \n",
    "\n",
    "**Key Takeaways:**\n",
    "- The Iris dataset is well-separated, making it perfect for learning ML concepts\n",
    "- Logistic Regression achieved perfect accuracy, indicating the classes are linearly separable\n",
    "- Feature importance analysis shows which measurements are most predictive of species\n",
    "- This pipeline can be applied to other classification problems with appropriate modifications\n",
    "\n",
    "**Next Steps:**\n",
    "- Try with more complex datasets\n",
    "- Experiment with different algorithms (Random Forest, SVM, Neural Networks)\n",
    "- Add cross-validation for more robust evaluation\n",
    "- Implement feature scaling and other preprocessing steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".ipynb",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}