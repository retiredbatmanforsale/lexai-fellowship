{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a56c2b-9997-4b0c-8b82-2eca5d0225c3",
   "metadata": {},
   "source": [
    "We are looking at how to compute the derivatives of the **cost function** for linear regression. The cost function is:\n",
    "\n",
    "$$\n",
    "J(m, c) = \\sum_{i=1}^n \\left( y_i - (mx_i + c) \\right)^2\n",
    "$$\n",
    "\n",
    "\n",
    "### What are we trying to do?\n",
    "\n",
    "We are trying to **minimize** the total error between our predicted line $\\hat{y}_i = mx_i + c$ and the actual data $y_i$. The total error is the **sum of squared differences** (residuals).\n",
    "\n",
    "To do this, we want to find values of $m$ (slope) and $c$ (intercept) such that this error is the smallest. In math, we do this by computing the **derivatives**‚Äîwhich tell us the direction in which the function is increasing or decreasing.\n",
    "\n",
    "\n",
    "\n",
    "### Derivative Intuition\n",
    "\n",
    "Imagine you are walking on a hilly surface (the graph of the function). The **derivative** tells you the slope of the hill at your feet. If the slope is steeply upwards, go the other way! If it's steeply downwards, keep going‚Äîit means you're minimizing the function.\n",
    "\n",
    "\n",
    "### Let's write the cost function again:\n",
    "\n",
    "$$\n",
    "J(m, c) = \\sum_{i=1}^n \\left( y_i - (mx_i + c) \\right)^2\n",
    "$$\n",
    "\n",
    "Let‚Äôs simplify this inner expression a bit. For each data point:\n",
    "\n",
    "$$\n",
    "\\text{error}_i = y_i - (mx_i + c)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{error}_i^2 = \\left( y_i - (mx_i + c) \\right)^2\n",
    "$$\n",
    "\n",
    "So our goal is to **adjust** $m$ and $c$ to reduce the total squared error.\n",
    "\n",
    "---\n",
    "\n",
    "## Derivative with respect to **m** (slope)\n",
    "\n",
    "We're going to ask: ‚ÄúHow does the error change if we nudge the slope $m$ a little bit?‚Äù\n",
    "\n",
    "Let‚Äôs derive $\\frac{\\partial J}{\\partial m}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial m} = \\sum_{i=1}^n 2 \\cdot \\left( y_i - (mx_i + c) \\right) \\cdot (-x_i)\n",
    "$$\n",
    "\n",
    "Why this form?\n",
    "\n",
    "* $2 \\cdot \\text{error}$: Comes from squaring a value (recall: $d/dx[x^2] = 2x$)\n",
    "* $-x_i$: Comes from chain rule; you're changing $m$, and the inside has $-mx_i$, which gives derivative $-x_i$\n",
    "\n",
    "So, putting it all together:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial m} = -2 \\sum_{i=1}^n x_i \\cdot \\left( y_i - (mx_i + c) \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Derivative with respect to **c** (intercept)\n",
    "\n",
    "Same logic, but now we ask: ‚ÄúWhat if we nudge the intercept $c$?‚Äù\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial c} = \\sum_{i=1}^n 2 \\cdot \\left( y_i - (mx_i + c) \\right) \\cdot (-1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial c} = -2 \\sum_{i=1}^n \\left( y_i - (mx_i + c) \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Derivatives\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial m} = -2 \\sum_{i=1}^n x_i \\cdot \\left( y_i - (mx_i + c) \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial c} = -2 \\sum_{i=1}^n \\left( y_i - (mx_i + c) \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ What do you do with these?\n",
    "\n",
    "You use them in **gradient descent**:\n",
    "\n",
    "* Repeatedly update:\n",
    "\n",
    "  $$\n",
    "  m := m - \\alpha \\cdot \\frac{\\partial J}{\\partial m}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  c := c - \\alpha \\cdot \\frac{\\partial J}{\\partial c}\n",
    "  $$\n",
    "* Where $\\alpha$ is the **learning rate** (a small number like 0.01)\n",
    "\n",
    "---\n",
    "\n",
    "Would you like a visual or Python code to compute this using example data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12233465-3caf-4a2e-ad7c-1274c3e2e237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
