# 🧠 April '25 Lex AI Fellowship · *Zero to ML-Hero*

<div align="center">
  <table>
    <tr>
      <td align="center">
        <img src="https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/brand-logos/lexai.png" alt="LexAI Logo" height="100"/>
      </td>
      <td align="center">
        <img src="https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/brand-logos/aiseekhegaindia.png" alt="AI Seekhega India Logo" height="100"/>
      </td>
    </tr>
  </table>
</div>

Welcome to the **Lex AI Fellowship** : a deep dive into the mathematical soul of machine learning.  
From first principles to hands-on implementation, this program is your personal fastlane into the world of **Linear Algebra, Calculus, Machine Learning, Deep Learning, Transformers, Language Models**, and real-world intelligence.

> 💡 Whether you're a startup founder, autodidact, or engineer hungry for first principles, this is your mathematical & applied AI dojo.

---

## 🧾 Curriculum Map

Each session is a blend of code, theory, and intuition - designed to make concepts *stick* and scale your mental models.

| 🔢 #  | 🧠 Title | 📂 Notebook | 🧰 Concepts & Takeaways |
|------|---------|-------------|-------------------------|
| 01 | ML Primer + Iris Intro | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/logistic_iris.ipynb) | • What is ML really?<br>• Classification 101<br>• Intro to workflows |
| 02 | LA 101 + Z-Score + PCA Peek | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/linear_algebra_transformations.ipynb) | • Vectors as transformations<br>• Z-score intuition<br>• Prepping for PCA |
| 03 | Eigen Intuition + Covariance | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/linear_algebra_eigenvalues_eigenvectors.ipynb) | • Eigendecomposition<br>• Covariance and correlation<br>• Geometric view of PCA |
| 04 | PCA: From Theory to Practice | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/pca_case_study.ipynb) | • Real-world PCA<br>• Dimensionality reduction<br>• Feature compression |
| 05 | Calculus: Linear Reg Cost Function | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/calculus_linear_regression_cost_function.ipynb) | • Loss function math<br>• Gradient Descent from scratch<br>• Cost surface intuition |
| 06 | Calculus: Logistic Reg Cost Function | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/calculus_linear_regression_cost_function.ipynb) | • Sigmoid & log loss<br>• Optimization dynamics<br>• Probabilistic interpretation |
| 07 | Linear Regression: Code it Yourself | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/LinearRegression1.ipynb) | • Pure Python implementation<br>• Model diagnostics<br>• Train/test splits |
| 08 | Logistic Regression: Iris Case Study | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/logistic_regression_case_study_iris.ipynb) | • Multiclass classification<br>• Confusion matrix<br>• Metrics that matter |
| 09 | Logistic Regression: From First Principles | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/logistic_regression_in_depth.ipynb) | • Code from scratch<br>• Gradient math<br>• Probabilities and decision boundaries |
| 10 | Linear Regression: Visual Cost Landscapes | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/linear_regression_case_study.ipynb) | • Cost vs weight curve<br>• Gradient visuals<br>• Convex optimization intuition |
| 11 | Bias-Variance: The Ultimate Tradeoff | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/bias_variance_plots.ipynb) | • Overfitting vs underfitting<br>• U-shaped loss<br>• Model complexity analysis |
| 12 | Clustering: Theory & Code | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/clustering_theory_and_implementation.ipynb) | • K-means demystified<br>• Distance metrics<br>• Visualizing clusters |
| 13 | ML Cheat Sheet | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/ml_cheat_sheet.ipynb) | • Quick theory refresh<br>• Code snippets<br>• Intuition bombs |

| 14 | Neural Networks | [📘](https://github.com/retiredbatmanforsale/lexai-fellowship/blob/main/neural_network_scratch.ipynb) | • NN theory<br>• Implementation <br>• Intuition bombs |
---

## 🧠 Pedagogy

- 🧬 **First Principles Only** — We don't treat AI like magic. We open the black box and teach you how to build one.
- 💻 **Code-Along Philosophy** — Every concept backed by live code in Jupyter.
- 🧭 **Conceptual Anchors** — Visuals, analogies, and mental models over rote formulas.
- 🔁 **Repetition = Retention** — Deliberate overlap of topics to deepen understanding.

---

## 🔗 How to Use This Repo

```bash
git clone https://github.com/retiredbatmanforsale/lexai-fellowship.git
cd lexai-fellowship
# Open any notebook in Jupyter or Colab
```

## 📎 Metadata
- 🧑‍🚀 Author: [Puru Kathuria](purukathuria.com)
- 📅 Fellowship: April 2025 Batch
- 🌐 Website: [www.lexailabs.com](www.lexailabs.com) | [www.aiseekhegaindia.com](www.aiseekhegaindia.com) 

## ⭐ Bonus

If this helped you, consider starring ⭐ the repo.
Fork it, remix it, or contribute your own notebooks as part of the next cohort.

Let's bring ML literacy to everyone.
